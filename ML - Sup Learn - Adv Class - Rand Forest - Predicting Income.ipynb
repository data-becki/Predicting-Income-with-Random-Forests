{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9afa7c",
   "metadata": {},
   "source": [
    "## Predicting Income with Random Forests\n",
    "\n",
    "In this project, we will be using a dataset containing census information from UCI’s Machine Learning Repository.\n",
    "\n",
    "By using this census data with a random forest, we will try to predict whether or not a person makes more than $50,000.\n",
    "\n",
    "Let’s get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7bf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d5825",
   "metadata": {},
   "source": [
    "## Investigate The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26d3bf",
   "metadata": {},
   "source": [
    "1. Let’s begin by investigating the data available to us. Click on the file `income.csv` and take a look. Notice the first row of the dataset contains the names of our columns. What columns do you think might be helpful in predicting a person’s income?\n",
    "\n",
    "    You can find more detailed descriptions of the columns on UCI’s Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/census%20income\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d06031",
   "metadata": {},
   "source": [
    "2. Go back to the `income.py` file. We want to get all of that data into a Pandas DataFrame. Use the `pd.read_csv()` function using `\"income.csv\"` as a parameter and store the result in a variable named `income_data`. Since the first row of our file contains the names of the columns, we also want to add the argument `header = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd2b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = pd.read_csv('income.csv', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0172d7c",
   "metadata": {},
   "source": [
    "3. Take a look at one of the rows of the data we’ve imported. Print `income_data.iloc[0]` to see the first row in its entirety. Did this person make more than $50,000? What is the name of the column that contains that information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39087856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                            39\n",
       " workclass              State-gov\n",
       " fnlwgt                     77516\n",
       " education              Bachelors\n",
       " education-num                 13\n",
       " marital-status     Never-married\n",
       " occupation          Adm-clerical\n",
       " relationship       Not-in-family\n",
       " race                       White\n",
       " sex                         Male\n",
       " capital-gain                2174\n",
       " capital-loss                   0\n",
       " hours-per-week                40\n",
       " native-country     United-States\n",
       " income                     <=50K\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b4aca",
   "metadata": {},
   "source": [
    "4. There’s a small problem with our data that is a little hard to catch — every string has an extra space at the start. For example, the first row’s native-country is `\" United-States\"`, but we want it to be `\"United-States\"`. This is happening because in `income.csv` there are spaces after the commas. To fix this, we can add the parameter `delimiter = \", \"` to our `read_csv()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c5a6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = pd.read_csv(\"income.csv\", header = 0, delimiter = \", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3747c",
   "metadata": {},
   "source": [
    "## Format The Data For Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5552900",
   "metadata": {},
   "source": [
    "5. Now that we have our data imported into a DataFrame, we can begin putting it in a format that our Random Forest can work with. To do this, we need to separate the labels from the rest of the data.\n",
    "\n",
    "    For this project, the labels are in the column called `\"income\"`. We want to grab only this column. You can get a single column from a DataFrame using this syntax:\n",
    "\n",
    "        one_column = data_frame_name[[\"column_name\"]]\n",
    "\n",
    "    Create a variable named `labels` that contains only the column `\"income\"` from the `income_data` DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbbd3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = income_data[[\"income\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98199a",
   "metadata": {},
   "source": [
    "6. We’ll also want to pick which columns to use when trying to predict income. For now, let’s select `\"age\"`, `\"capital-gain\"`, `\"capital-loss\"`, `\"hours-per-week\"`, and `\"sex\"`. Create a new variable named `data` that contains only those columns. The syntax for this is very similar to selecting only one column:\n",
    "\n",
    "        many_columns = data_frame_name[[\"a\", \"b\", \"c\"]]\n",
    "\n",
    "    In this example, `many_columns` now contains the columns `\"a\"`, `\"b\"`, and `\"c\"` from `data_frame_name`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7da80210",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = income_data[[\"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"sex\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260123b",
   "metadata": {},
   "source": [
    "7. Finally, we want to split our data and labels into a training set and a test set. We’ll use the training set to build the random forest, and the test set to see how accurate it is. Use the `train_test_split()` function to do this.\n",
    "\n",
    "    `train_test_split()` returns four values — name them `train_data`, `test_data`, `train_labels`, and `test_labels`. When calling `train_test_split()`, it should take three arguments — `data`, `labels` and `random_state = 1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2207be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e48df",
   "metadata": {},
   "source": [
    "## Create The Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b71b90",
   "metadata": {},
   "source": [
    "8. We’re now ready to use this data to build and test our random forest. First, create a `RandomForestClassifier` and name it `forest`. When you create the random forest, use the parameter `random_state = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca38ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc390050",
   "metadata": {},
   "source": [
    "9. Next, we need to fit the model. We want to use the training data and training labels to train the random forest.\n",
    "\n",
    "    Call forest‘s `.fit()` method using `train_data` and `train_labels` as parameters. When you run your code, there should be an error!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "112ac98b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Female'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3532/2554993050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[1;32m--> 304\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Female'"
     ]
    }
   ],
   "source": [
    "forest.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc0049",
   "metadata": {},
   "source": [
    "10. There seems to be a problem with using the column `\"sex\"` when training the random forest.\n",
    "\n",
    "    In that column, there are values like `\"Male\"` and `\"Female\"`. Random forests can’t use columns that contain Strings — they have to be continuous values like integers or floats. We’ll solve this problem soon, but for now, let’s remove the `\"sex\"` column when creating data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae50e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = income_data[[\"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]]\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state = 1)\n",
    "forest = RandomForestClassifier(random_state = 1)\n",
    "forest.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed18991",
   "metadata": {},
   "source": [
    "11. Now that our training set doesn’t have a column containing strings, we have successfully fit our random forest.\n",
    "\n",
    "    We can now test its accuracy. Call forest‘s `.score()` method using `test_data` and `test_labels` as parameters. Print the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1f96f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222577078982926"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3f1f3",
   "metadata": {},
   "source": [
    "## Changing Column Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b92c9",
   "metadata": {},
   "source": [
    "12. Now that we know the random forest works, let’s go back and try to add the `\"sex\"` column.\n",
    "\n",
    "    Recall that the problem was that this column contained strings. If we transformed those strings into integers, we could use this data!\n",
    "\n",
    "    If we take every row and make every `\"Male\"` a `0` and every `\"Female\"` a `1`, we could then use the column in our random forest. Before creating the data variable, use this line of code:\n",
    "\n",
    "        income_data[\"sex-int\"] = income_data[\"sex\"].apply(lambda row: 0 if row == \"Male\" else 1)\n",
    "\n",
    "    This creates a new column called `\"sex-int\"` in the `income_data` DataFrame. Every row in that new column contains a `0` if the row’s `\"sex\"` column contained `\"Male\"` and a `1` otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7abac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data[\"sex-int\"] = income_data[\"sex\"].apply(lambda row: 0 if row == \"Male\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db303b1e",
   "metadata": {},
   "source": [
    "13. Add `\"sex-int\"` to your list of columns included in data. What is your accuracy now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a84943ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8272939442328953"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = income_data[[\"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"sex-int\"]]\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state = 1)\n",
    "forest = RandomForestClassifier(random_state = 1)\n",
    "forest.fit(train_data, train_labels)\n",
    "forest.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a42f7",
   "metadata": {},
   "source": [
    "14. There are a couple of other columns that use strings that might be useful to use. Let’s try transforming the values in the `\"native-country\"` column.\n",
    "\n",
    "    We should first take a look at the different values that exist in the column. Print `income_data[\"native-country\"].value_counts()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc29bd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United-States                 29170\n",
       "Mexico                          643\n",
       "?                               583\n",
       "Philippines                     198\n",
       "Germany                         137\n",
       "Canada                          121\n",
       "Puerto-Rico                     114\n",
       "El-Salvador                     106\n",
       "India                           100\n",
       "Cuba                             95\n",
       "England                          90\n",
       "Jamaica                          81\n",
       "South                            80\n",
       "China                            75\n",
       "Italy                            73\n",
       "Dominican-Republic               70\n",
       "Vietnam                          67\n",
       "Guatemala                        64\n",
       "Japan                            62\n",
       "Poland                           60\n",
       "Columbia                         59\n",
       "Taiwan                           51\n",
       "Haiti                            44\n",
       "Iran                             43\n",
       "Portugal                         37\n",
       "Nicaragua                        34\n",
       "Peru                             31\n",
       "France                           29\n",
       "Greece                           29\n",
       "Ecuador                          28\n",
       "Ireland                          24\n",
       "Hong                             20\n",
       "Cambodia                         19\n",
       "Trinadad&Tobago                  19\n",
       "Laos                             18\n",
       "Thailand                         18\n",
       "Yugoslavia                       16\n",
       "Outlying-US(Guam-USVI-etc)       14\n",
       "Honduras                         13\n",
       "Hungary                          13\n",
       "Scotland                         12\n",
       "Holand-Netherlands                1\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be2554",
   "metadata": {},
   "source": [
    "15. Since the majority of the data comes from `\"United-States\"`, it might make sense to make a column where every row that contains `\"United-States\"` becomes a `0` and any other country becomes a `1`. Use the syntax from creating the `\"sex-int\"` column to create a `\"country-int\"` column.\n",
    "\n",
    "    When mapping Strings to numbers like this, it is important to make sure that continuous numbers make sense. For example, it wouldn’t make much sense to map `\"United-States`\" to `0`, `\"Germany\"` to `1`, and `\"Mexico\"` to `2`. If we did this, we’re saying that Mexico is more similar to Germany than it is to the United States.\n",
    "\n",
    "    However, if you had values in a column like `\"low\"`, `\"medium\"`, and `\"high\"` mapping those values to `0`, `1`, and` 2 `would make sense because their representation as Strings is also continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ad16462",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data[\"country-int\"] = income_data[\"native-country\"].apply(lambda row: 0 if row == \"United_states\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667b772",
   "metadata": {},
   "source": [
    "16. Add `\"country-int\"` to the columns used when creating data. How does this change the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db63a35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8276624493305491"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = income_data[[\"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"sex-int\", \"country-int\"]]\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state = 1)\n",
    "forest = RandomForestClassifier(random_state = 1)\n",
    "forest.fit(train_data, train_labels)\n",
    "forest.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb86b129",
   "metadata": {},
   "source": [
    "17. Now that you’ve gotten the hang of transforming, adding, and removing columns from your training data, it’s time to explore on your own to try to make the best classifier possible.\n",
    "\n",
    "    As you play around with the data, here are some ideas that you might want to try:\n",
    "\n",
    "    -    Create a `tree.DecisionTreeClassifier`, train it, test it using the same data, and compare the results to the random forest. When does the random forest do better than the single tree? When does a single tree do just as well as the forest?\n",
    "    -    After calling `.fit()` on the forest, print `forest.feature_importances_`. This will show you a list of numbers where each number corresponds to the relevance of a column from the training data. Which features tend to be more relevant?\n",
    "    -    Use some of the other columns that use continuous variables, or transform columns that use strings!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21ac0e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30707084, 0.3047428 , 0.1214073 , 0.2007971 , 0.06598195,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c678563",
   "metadata": {},
   "source": [
    "*`age` and `capital-gain` are more relevant.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
